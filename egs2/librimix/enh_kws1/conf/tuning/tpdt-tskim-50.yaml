optim: adam
init: xavier_uniform
max_epoch: 100
batch_type: folded
batch_size: 360 # 64
iterator_type: chunk
chunk_length: 24000
num_workers: 4
optim_conf:
    lr: 1.0e-03
    eps: 1.0e-08
    weight_decay: 0
patience: 50
val_scheduler_criterion:
- valid
- loss
best_model_criterion:
-   - valid
    - si_snr
    - max
-   - valid
    - loss
    - min
keep_nbest_models: 20
chunk_excluded_key_prefixes: 
- wkp_ind

scheduler: steplr
scheduler_conf:
    step_size: 1
    gamma: 0.97
encoder: conv
encoder_conf:
    channel: 128
    kernel_size: 32
    stride: 16
decoder: conv
decoder_conf:
    channel: 128
    kernel_size: 32
    stride: 16
separator: tskim
separator_conf:
    causal: False
    num_spk: 2
    layer: 6
    nonlinear: relu
    unit: 256
    segment_size: 48
    dropout: 0.1
    mem_type: hc
    seg_overlap: True
    fusioner: conformer
    fusioner_conf:
        hidden_dim: 128
        condition: dump/raw/train-s2m-min/cond50.scp
        # text_condition: None    # todo
        # audio_condition: None   # todo

# A list for criterions
# The overlall loss in the multi-task learning will be:
# loss = weight_1 * loss_1 + ... + weight_N * loss_N
# The default `weight` for each sub-loss is 1.0
criterions:
  # The first criterion
  - name: si_snr
    conf:
      clamp_db: 50
    wrapper: tpdt
    wrapper_conf:
      weight: 1.0
      independent_perm: True
